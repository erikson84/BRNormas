```{r, include=FALSE}
library(ggplot2)
library(gridExtra)
library(knitr)
library(kableExtra)
```

# Fundamentação estatística para normas baseadas em regressão

## Dificuldades em estabelecer medidas em Psicologia

Na Física e nas demais ciências naturais, uma *medida* é definida pelo produto de uma *magnitude* de um atributo quantitativo com uma unidade fundamental de referência. É crucial que a relação entre diferentes magnitudes, como proposta por equações de modelos científicos, seja independente da unidade fundamental utilizada para expressar a medida. Essa *invariância* com relação à unidade de referência utilizada para expressar uma medida só é possível quando a operacionalização do processo de mensuração do atributo quantitativo resulta em valores que permitam a operação de divisão, i.e., ser possível e significativo calcular *razões* entre duas medidas.

Nas Psicologia, via de regra, esse nível de mensuração não costuma ser proposto ou mesmo tentado. Em seu lugar, a Psicologia aceitou amplamente a noção *operacionalista* de mensuração, na qual um atributo quantitativo é definido pelo processo estipulado para sua mensuração. Nesse contexto, uma medida é simplesmente um conjunto de regras que permite atribuir valores numéricos a atributos, independente de sua natureza. Apesar de o operacionalismo permitir ampliar a noção de medida e justificar *a priori* a possibilidade de mensuração de qualquer construto psicológico, os valores numéricos obtidos pela aplicação de regras arbitrárias de mensuração não mantém a estrutura matemática necessária para a realização de operações básicas. Dessa forma, não é possível estabelecer razões entre diferentes medidas e, portanto, não faz sentido tentar estabelecer uma unidade fundamental de referência.

## O papel das normas estatísticas

Mas nem tudo está perdido para as mensurações possíveis de serem obtidas por meio de instrumentos psicológicos. Na ausência de uma unidade fundamental de referência que dê sentido às magnitudes obtidas, a Psicologia propõe a comparação dos valores resultantes da avaliação de um sujeito numa determinada medida definida por um instrumento psicológico à *distribuição de probabilidade* dessa medida em uma população de referência, chamada de *população normativa*. A Psicologia substitui, então, a necessidade de uma unidade de medida por um critério estatístico de comparação, permitindo pelo menos o ordenamento de diferentes sujeitos com relação ao atributo de interesse (ou, mais especificamente, aos valores obtidos pelo processo de mensuração associado a um construto postulado).

Essa comparação da medida de um sujeito à população normativa pode ser expressa de diversas maneiras, mas, a título de generalidade, vamos supor que o ordenamento permita, minimamente, estabelecer o *percentil* ao qual o sujeito avaliado pertence. O *percentil* é definido como a probabilidade (aqui também possível de ser entendida como proporção) de uma variável aleatória *X* ser inferior ou igual a um valor fixo *x*.

$$\mathrm{Percentil}(x) = \mathrm{Pr}(X \leq x)$$

Em uma situação ideal, se conseguimos observar todos os valores de um população normativa finita, e supondo que o processo de mensuração atribua números pertencentes a um conjunto ordenado e finito (ou pelo menos contável), a distribuição de probabilidade de referência pode ser expressa como um histograma e o percentil de um sujeito pode ser facilmente computado calculando a proporção entre os casos com valores menores ou iguais ao valor observado e o tamanho total da população.

:::: {.examplebox data-latex=""}
::: {.center data-latex=""}

**Exemplo**

:::

Um item com enunciado "Eu me sinto disposto ao acordar" é avaliado em uma escala ordinal com cinco alternativas ordenadas -- "Discordo Fortemente, "Discordo", "Nem concordo, nem discordo", "Concordo", "Concordo Fortemente" -- codificados como números inteiros dentro do intervalo [1, 5]. Vamos supor que a população normativa possua 700 pessoas e o item tenha sido aplicado em todos os sujeitos, resultando na seguinte distribuição de frequência:

```{r}
samp_data <- data.frame(Valor=1:5,
                        Frequência=c(60, 150, 260, 190, 40))
kable(samp_data, booktabs=T, caption='Histograma de frequência dos valores numa população finita')
```

Nesse exemplo idealizado, há apenas cinco valores possíveis para os percentis: quem obtém escore igual a um pertence ao percentil 8,6% ($\frac{60}{700}$); quem obtém escore igual a dois pertence ao percentil 30% ($\frac{60 + 150}{700}$); quem obtém escore igual a três pertence ao percentil 67,1% ($\frac{60 + 150 + 260}{700}$); quem obtém escore igual a quatro pertence ao percentil 94,3% ($\frac{60 + 150 + 260 + 190}{700}$); e, por fim, quem obtém escore igual a cinco pertence ao percentil 100% ($\frac{60 + 150 + 260 + 190 + 40}{700}$).

O uso do percentil como medida de comparação entre a resposta de um sujeito e a população normativa também pode ser visualizado graficamente por meio de um histograma. Na figura abaixo, um sujeito que escolheu a alternativa "Concordo", codificada com valor quatro, tem sua posição com relação à população identificada por meio da linha vertical tracejada. Toda a população que escolheu um valor igual ou menor desse sujeito está representada pelas barras em cor azul; o restante da população está representada pela barra em cor vermelha. O percentil é computado pela soma do número de respondentes em cada barra em cor azul dividida pelo tamanho total da população.

```{r, fig.align='center', fig.cap='Histograma de Frequência de respostas na população'}
ggplot(samp_data, aes(x=Valor, y=Frequência)) +
  geom_bar(stat='identity', fill=ifelse(samp_data$Valor <= 4, 'steelblue', 'maroon')) +
  geom_vline(xintercept=4, linetype=2)
```

::::

## Dois desafios: aproximação e estimação

Para muitas medidas -- especialmente aquelas derivadas da soma ou média de diversos itens de um instrumento -- o número resultante da operação de mensuração pode variar em muitos níveis e, mesmo que esse níveis sejam finitos e não estritamente contínuos, podemos tratar a medida como propriamente contínua. Mesmo que, teoricamente, algum instrumento pudesse produzir resultados contínuos, o fato de as populações serem invariavelmente finitas implica que só um número finito de possibilidades podem ser efetivamente observado. Ainda assim, pode ser frutífero considerar a medida como contínua e avaliar seu percentil a partir de uma função de distribuição acumulada.

O desafio de suavizar a função de distribuição acumulada de uma população finita -- supondo que ela pode ser observada por completo -- traz um primeiro desafio de como melhor *aproximar* uma distribuição descontínua por uma função contínua. Essa questão, todavia, torna-se secundária quando é impossível observar a população normativa por completo -- o que é mais comumente a regra do que a exceção. Nesse caso, o segundo e principal desafio é de como *estimar* a função de distribuição acumulada tendo acesso exclusivamente a uma amostra da população normativa.

Ambos os desafios costumam ser resolvidos de uma só vez por meio da adoção de um *modelo* estatístico para descrever a população. Mesmo que a população e os valores produzidos pelo processo de mensuração sejam finitos, a população é modelada por uma função de distribuição de probabilidade com suporte contínuo. Tradicionalmente, é escolhida uma função de probabilidade que pode ser descrita por um número finito de parâmetros; em particular, a distribuição Gaussiana ou Normal, indexada apenas pelos parâmetros de média e variância, é comumente empregada para descrever a população e indicar os parâmetros de interesse para obtenção da função de distribuição acumulada^[A literatura estatística apresenta alternativas variadas para a aproximação da função de distribuição acumulada, desde o uso da distribuição acumulada empírica para os valores obtidos para a amostra -- que pode ser bastante ruidoso, especialmente nas caudas -- até estratégia de suavização não-paramétricas baseadas em *kernels* gaussianos ou em processos de Dirichlet. Como meio caminho existe a possibilidade de utilizar formas funcionais de famílias paramétricas, supondo que a família representa adequadamente a distribuição da população.].

:::: {.examplebox data-latex=""}
::: {.center data-latex=""}

**Exemplo**

:::

Um teste de inteligência geral com 20 itens é aplicado em uma população de 500 estudantes. Por definição, os escores derivados deste teste são discretos: somente 21 valores são possíveis. Além disso, a própria população de referência é finita, formada por 500 pessoas. A função de distribuição acumulada, calculada de forma empírica para todas as observações e suavizadas pela aproximação gaussiana, é apresentada na Figura 2. É importante destacar que a utilização da aproximação Gaussiana nesse caso cumpre exclusivamente a função de *aproximação* e *suavização* da função empírica.

A figura também apresenta três estimativas dessa função de distribuição acumulada com base em amostras aleatórias simples de 30 sujeitos dessa população. Nesse caso, a aproximação Gaussiana cumpre o duplo papel mencionado acima: simultaneamente, ela permite *aproximar* a distribuição da população e facilita a *estimação* da função populacional por meio das estatísticas calculadas a partir da amostra.

```{r, fig.cap='Distribuição acumulada dos escores de QI na população e em três amostras aleatórias'}
pop_data <- round(rnorm(500, 10, 2))

plot_pop <- ggplot(data.frame(QI=pop_data), aes(x=QI)) + stat_ecdf(aes(color='Distribuição Empírica')) + 
  geom_function(fun=function(x) pnorm(x+0.5, mean(pop_data), sd(pop_data)), aes(color='Suavização Gaussiana')) +
  labs(y='Pr(QI <= x)', color='Legenda') + 
  scale_color_manual(values=c('Distribuição Empírica'='steelblue', 'Suavização Gaussiana'='maroon'))

plot_list <- list(pop=plot_pop)

for (pl in c('samp1', 'samp2', 'samp3')) {
  samp <- sample(pop_data, 30)
  plot_df <- data.frame(QI=samp)
  plot_samp <- ggplot(plot_df, aes(x=QI)) + stat_ecdf(color='steelblue') + 
    geom_line(data=data.frame(x=seq(4, 16, length.out=100), y=pnorm(seq(4, 16, length.out=100), mean(samp), sd(samp))),
              aes(x=x, y=y), color='maroon') + 
    geom_function(fun=function(x) pnorm(x+0.5, mean(pop_data), sd(pop_data)), color='black', linetype=2) +
    labs(y='Pr(QI <= x)') + theme(legend.position = 'none') + xlim(3, 16)
  
  plot_list[[pl]] <- plot_samp

}

grid.arrange(grobs=plot_list, layout_matrix=rbind(c(1, 1, 1), c(2, 3, 4)))


```
Qual a vantagem de utilizar a aproximação Gaussiana neste exemplo? Para os dados da população completa, a vantagem é meramente de compressão de dados: em vez de armazenar 500 observações para calcular a função acumulada, podemos obter a mesma precisão com apenas dois números: a média e a variância -- assumindo, é claro, que a forma funcional é adequada para aproximar a distribuição da população.

No caso de utilizar a aproximação Gaussiana para facilitar a estimação da função de distribuição acumulada, há uma segunda vantagem -- também condicional à boa aproximação da forma funcional pela distribuição Normal: o erro no percentil obtido a partir da aproximação normal será menor do que o percentil obtido pela função de distribuição acumulada empírica, especialmente para amostras menores. Isso fica evidente nos gráficos acima: a curva estimada pela aproximação Gaussiana (em vermelho escuro) se aproxima da curva baseada nos parâmetros populacionais (em preto tracejado); a aproximação por meio da função de distribuição acumulada empírica (em azul) apresenta maior variação e, portanto, maior erro.

::::

## Populações heterogêneas

Se a população normativa de um escala psicológica é relativamente homogênea ou se o atributo mensurado não varia sistematicamente em função de outras variáveis, uma única tabela normatiza é suficiente. Porém, esse nível de homogeneidade raramente é observado para variáveis psicológicas: elas são afetadas por diversos fatores com diferentes graus de magnitude. Nesses casos, uma única referência normativa pode ser inadequada, a depender dos objetivos propostos para a avaliação.

No caso de populações heterogêneas, precisamos identificar as fontes relevantes de variação e elaborar uma tabela normativa para cada nível pertinente dessas fontes. Em outras palavras, precisamos encontrar a *função de distribuição acumulada condicional* (FDA) da medida de interesse em função dos diferentes valores das variáveis influenciadoras.

$$\mathrm{FDA}(x \mid Y=y, \dots, Z=z) = \mathrm{Pr}(X \leq x \mid Y=y, \dots, Z=z)$$
A maioria dos testes psicológicos elege um pequeno número de variáveis sociodemográficas consideradas relevantes e elabora uma tabela normativa para cada um dos níveis dessas variáveis, geralmente de forma separada (i.e.: sem considerar o efeito conjunto de níveis dos preditores). Apesar de ser um avanço sobre a apresentação de uma única tabela normativa, as limitações desse procedimento são óbvias:

1. Só é possível escolher variáveis discretas ou discretizar variáveis contínuas em classes amplas; 
2. É difícil considerar como condicionante mais de uma variável por vez, levando a construção de tabelas, p.ex., para gênero ou escolaridade mas não para gênero e escolaridade simultaneamente; 
3. O cálculo dos valores dessa tabela, se feito de forma exclusivamente empírica, subdividindo a amostra de acordo com os níveis das variáveis condicionantes, terá um número menor de pontos de dados e será mais ruidoso.

De maneira geral, o problema estatístico de estimar valores para um *desfecho* de interesse (em nosso caso, uma medida psicológica), que passaremos a representar como *y*, em função dos valores condicionais de um ou mais *preditores* (como variáveis sociodemográficas ou outras pertinentes ao atributo avaliado), que representaremos pelo vetor **x**, é endereçado por uma classe de modelos chamados de *modelos de regressão*. A maioria dos modelos de regressão buscar estimar o valor esperado do desfecho condicionado nos níveis observados dos preditores. Em particular, os modelos de *regressão linear* tentam aproximar essa função pela combinação aditiva dos preditores, ponderados por coeficientes de inclinação ($\boldsymbol{\beta}$, na equação abaixo).

$$\mathbb{E}(y_i\mid\textbf{x}_i, \boldsymbol{\beta})=\alpha + \beta_1x_{i1}+\dots+\beta_kx_{ik}$$

## Regressão linear

Via de regra, a distribuição condicional de probabilidade $p(y\mid\boldsymbol{x})$ não é conhecida e as dependências entre a variável alvo e as variáveis condicionantes podem ser mais complexas do que é possível capturar com um modelo estatístico paramétrico. Mesmo assim, uma aproximação inicial pode ser obtida se for plausível assumir algumas simplificações:

1. A variação média de um desfecho em função da variação de um preditor é constante e não depende do valor específico do preditor -- esse pressuposto implica na *linearidade* da relação entre desfecho e preditores, e pode ser flexibilizado pelo acréscimo de polinômios dos preditores com relação não-linear;
2. A maneira como um preditor influencia o desfecho não depende dos valores dos outros preditores -- esse pressuposto implica da *aditividade* dos preditores, e pode ser flexibilizado pelo acréscimo de combinações (*interações*) entre preditores com influência mútua;
3. Os valores mensurados para os preditores não possuem erro e podem ser tratados como fixos, ou, minimamente, os erros nos preditores podem ser desprezados sem consequência para as predições -- esse pressuposto de *exogeneidade fraca* implica que não precisamos considerar o modelo da distribuição conjunta de todas as variáveis;
4. A maneira como o valor observado difere do valor esperado predito pelo modelo -- os *erros* -- não depende nem do valor predito nem dos valores específicos dos preditores -- esse pressuposto determina a *independência dos erros* e não pode ser flexibilizado sem mudar fundamentalmente a estrutura do modelo (transformando-o, p.ex., em um modelo hierárquico para dar conta de dependência de erros entre grupos);
5. A variância dos erros é constante para qualquer valor predito e independe dos valores do preditores -- esse pressuposto implica na *homogeneidade da variância* dos erros do modelo e é assumido por algoritmos tradicionais, como mínimos quadrados e máxima verossimilhança, mas pode ser flexibilizado utilizando mínimos quadrados ponderados ou estimadores robustos para a Hessiana do modelo de máxima verossimilhança;
6. A *distribuição dos erros* segue uma função de densidade gaussiana -- esse pressuposto assume a *normalidade dos erros* e só é necessário porque nossa tarefa envolve calcular a função de distribuição acumulada para avaliar os percentis normativos e não é, de forma alguma, um pressuposto para a regressão linear para fins de predição do valor esperado do desfecho.

Mesmo que não disponhamos de informações *a priori* para avaliar se as simplificações assumidas por esses pressupostos são válidas para aproximarmos a distribuição condicional pelo modelo de regressão linear, o modelo ajustado pode ser verificado por meio de análises específicas que permitem diagnosticar a adequação razoável ou identificar desvios graves desse pressupostos. Mas para poder avaliar melhor a adequação de um modelo linear aproximativo, é importante ter clareza sobre alguns conceitos importantes sobre regressão, ilustrados na figura abaixo.

```{r, fig.align='center', fig.cap='Ilustração de conceitos de regressão linear'}
x <- rnorm(500, 2, 1)
y <- rnorm(500, 2 + 1.3*x, 1)

ggplot(data.frame(x=x, y=y), aes(x=x, y=y)) + geom_point(color='skyblue') +
  geom_abline(intercept=2, slope=1.3) +
  geom_path(data=data.frame(y=seq(2+1.3*1 - 3, 2+1.3*1 + 3, length.out=100),
                            x=dnorm(seq(2+1.3*1 - 3, 2+1.3*1 + 3, length.out=100),
                                    2+1.3*1, 1)/dnorm(0, 0, 1)+1), color='maroon') +
  geom_segment(aes(y=2+1.3*1 - 3, yend=2+1.3*1 + 3,
                   x=1, xend=1), linetype=2) +
  geom_path(data=data.frame(y=seq(2+1.3*3 - 3, 2+1.3*3 + 3, length.out=100),
                            x=dnorm(seq(2+1.3*3 - 3, 2+1.3*3 + 3, length.out=100),
                                    2+1.3*3, 1)/dnorm(0, 0, 1)+3), color='maroon') +
  geom_segment(aes(y=2+1.3*3 - 3, yend=2+1.3*3 + 3,
                   x=3, xend=3), linetype=2) + 
  geom_vline(xintercept=0, linetype=3) +
  annotate('text', x=0-0.3, y=2+0.5, label='alpha', parse=T, size=8) +
  geom_segment(aes(x=0-0.2, xend=0, y=2+0.4, yend=2),
               arrow=arrow(length=unit(0.2, 'cm'))) +
  annotate('text', x=4.5, y=9.2, label='E[y|x]', size=8) +
  geom_segment(aes(x=4.5, xend=4.7, y=9-0.3, yend=8.1),
               arrow=arrow(length=unit(0.2, 'cm'))) +
  annotate('text', x=2, y=1.05, label='p(y|x)', size=8) +
  geom_segment(aes(x=2-0.2, xend=2-0.4, y=1.25, yend=2),
               arrow=arrow(length=unit(0.2, 'cm'))) +
  geom_point(x=3, y=4, color='skyblue') +
  geom_point(x=3, y=4, color='black', size=5, shape=1, stroke=1) +
  geom_segment(aes(x=3-0.15, xend=3-0.15, y=4, yend=5.64),
               arrow=arrow(length=unit(0.2, 'cm'), ends='both')) +
  annotate('text', x=2.7, y=4.7, label='epsilon', parse=T, size=8) +
  geom_segment(aes(x=-1.5, xend=-0.5, y=0, yend=0), linetype=2) +
  geom_segment(aes(x=-0.5, xend=-0.5, y=0, yend=1.3), linetype=2) +
  annotate('text', x=-1, y=-0.5, label='a') +
  annotate('text', x=-0.3, y=0.65, label='b') +
  annotate('text', x=0.1, y=0, label='beta == frac(b, a)', parse=T, size=8)
  

```

O gráfico acima apresenta a dispersão dos pares (*x*, *y*) como pontos azuis num plano cartesiano. A variável condicionante -- também chamada de *preditor*, *covariável* ou *variável independente* -- é representada pela letra *x* no eixo horizontal. A variável condicionada -- também chamada de *desfecho*, *critério* ou *variável dependente* -- é representada pela letra *y* no eixo vertical.

A variável *x* não precisa ser considerada uma variável aleatória. Ela pode ter valores fixos, como acontece em um experimento em que ela é controlada pelo pesquisador. Mas ela também pode ser proveniente de um processo estocástico -- porém, para fins do modelo de regressão, seus valores são considerados fixos *a priori*, pelo pressuposto de exogeneidade fraca.

A reta preta em linha cheia que cruza os pontos indica a equação de regressão linear simples $\mathbb{E}[y_i\mid x_i]=\alpha + \beta_1x_i$. Ou seja: o valor esperado ou médio do desfecho *y* para o caso *i* é dado pela soma de uma valor constante $\alpha$ com o produto do preditor observado $x_i$ e um coeficiente $\beta_1$. A equação de regressão também pode ser interpretada como a média da subpopulação definida pelo valor observado do preditor: se observarmos vários casos com valor de $x=x_i$, a média dessas observações para a variável *y* é dada pela equação de regressão.

A letra grega $\alpha$ indica o valor constante da equação linear, chamado de *intercepto*. Esse valor simplesmente indica em que ponto a reta cruza o eixo vertical *y*. Sua interpretação depende o significado do valor zero para o preditor: se zero é um valor arbitrário, o intercepto não possui nenhum significado em particular; porém, se o preditor é centralizado na média, p.ex., o intercepto indica o valor médio do desfecho quando o preditor se encontra também na média. Por esse motivo, é comum centralizar os preditores em valores interpretáveis, tornando o intercepto uma quantidade de interessa para inferência.

O coeficiente que multiplica o preditor, indicado pela letra grega $\beta$, é denominado de *inclinação* da reta. Esse coeficiente indica a variação esperada no desfecho para cada unidade de diferença observada no preditor. Quando comparamos os valores de $x_1$ e $x_2$, tal que $x_2 - x_1 = a$, se o valor médio do desfecho correspondente a esses valores for igual a $y_1$ e $y_2$, respectivamente, tal que $y_2 - y_1 = b$, a inclinação da reta é dada pela razão entre *b* e *a*, $\beta=\frac{b}{a}$.

Nesse exemplo, a aproximação linear para a o valor esperado de *y* condicionado ao valor de *x* pode ser considerada adequada apenas por inspeção visual -- o que é esperado, já que o processo gerador de dados utilizado para simular esses valores é efetivamente linear. Como esse exemplo é baseado num modelo com um único preditor, o pressuposto de aditividade não é pertinente.

Os valores efetivamente observados para a variável *y*, porém, raramente vão coincidir exatamente com o valor esperado predito pela equação de regressão. Essa diferença entre o valor esperado e o valor observado é chamado de *erro* e costumeiramente representado pela letra grega $\epsilon$. No gráfico acima, uma observação específica para o par de observações (3, 4) é circulada para indicar sua localização. Esse valor observado é inferior ao valor médio esperado para os casos em que *x*=3, indicado pela linha vertical tracejada. A diferença entre o valor observado e o predito, $y_i - \mathbb{E}[y_i\mid x_i]$, é denotada pelo letra $\epsilon$.

Num modelo de regressão, esses erros são considerados puramente aleatórios e independentes entre si. Isso significa que os pontos observados devem estar mais ou menos igualmente dispersos em torno da reta de regressão, sem nenhum padrão evidente que sugira algum desvio sistemático dos valores preditos. Além disso, a variância desses erros, $\mathrm{var}[\epsilon]$ ou $\sigma^2_{\epsilon}$ é considerada homogênea para todos os pares possívei (*x*, *y*).

Como o comportamento dos erros é aleatório e com variância constante, a equação de regressão também pode ser utilizada para definir a distribuição condicional do desfecho em função do preditor, i.e., $\mathrm{p}(y_i\mid x_i)$. Essa distribuição condicional é representada no gráfico acima como os contornos de densidade em cor bordô para dois valores possíveis de *x*. A forma funcional usualmente assumida para essa distribuição é Gaussiana, mas é possível elaborar modelos lineares com outras formas funcionais para a distribuição condicional.

Uma informação relevante é que o método dos mínimos quadrados, um algoritmo comumente empregado para estimar um modelo de regressão, não assume nenhum pressuposto para a forma funcional dos erros aleatórios; porém, a otimização dos mínimos quadrados é matematicamente equivalente à estimação de máxima verossimilhança de um modelo que assume a distribuição normal para os erros. Por esse motivo, é comum assumir que os erros devem ter distribuição normal.

Se estamos interessados apenas na predição do valor esperado do desfecho, a forma funcional dos erros é pouco relevante. Porém, no caso do uso de modelos de regressão para estabelecimento de normas psicométricas, a forma funcional é crucial para determinar o percentil ao qual pertence o caso observado e a adequação da aproximação Gaussiana precisa ser avaliada.

Caso a aproximação linear e a forma funcional dos erros seja adequada para modelar os dados, o percentil de cada observação pode ser computado comparando o caso com a subpopulação definida pelos valores observados dos preditores por meio da função cumulativa normal:

$$\mathrm{FDA}(y_i \mid \textbf{x}_i) = \Phi\left(\frac{y_i - \mathbb{E}[y_i \mid \textbf{x}_i]}{\sigma_{\epsilon}}\right)$$

:::: {.examplebox data-latex=""}
::: {.center data-latex=""}

**Exemplo**

:::

Um teste de inteligência padronizado com média populacional igual a 100 e desvio-padrão igual a 15 possui uma distribuição marginal (i.e., sem considerar a distribuição conjunta com outras variáveis) simétrica e aproximadamente normal, conforme histograma na figura abaixo. Muitos estudos empíricos demonstram que os escores em testes de inteligência estão positivamente relacionados à escolaridade, com uma média de um a cinco pontos de QI adicionais para cada ano a mais de educação. Essa relação linear também é apresentada na figura como uma regressão linear simples, assumindo que o efeito dos anos de escolaridade é de três pontos de QI para cada ano adicional.

```{r, fig.align='center', fig.cap='Distribuição marginal e condicional de escores de um teste de inteligência em função dos anos de educação'}
edu <- round(rnorm(300, 12, 3))
qi <- round(rnorm(300, 100 + 3*(edu - 12), 12))

hist <- ggplot(data.frame(QI=qi), aes(x=QI)) + 
  geom_histogram(aes(y=after_stat(density)), fill='skyblue') + 
  ggtitle('Distribuição marginal') + ylab('Densidade') +
  geom_function(fun=function(x) dnorm(x, mean=100, sd=15)) +
  geom_vline(xintercept=100, linetype=2)
scat <- ggplot(data.frame(QI=qi, Educação=edu), aes(y=QI, x=Educação)) + 
  geom_point(color='skyblue') + geom_abline(intercept=100-12*3, slope=3) +
  geom_path(data=data.frame(QI=seq(109-3*12, 109+3*12, length.out=100),
                            Educação=dnorm(seq(109-3*12, 109+3*12, length.out=100),
                                           109, 12)/dnorm(20, 0, 12) + 15), color='maroon')+
  geom_path(data=data.frame(QI=seq(91-3*12, 91+3*12, length.out=100),
                            Educação=dnorm(seq(91-3*12, 91+3*12, length.out=100),
                                           91, 12)/dnorm(20, 0, 12) + 9), color='maroon')+
  geom_vline(xintercept=9, linetype=2) +
  geom_vline(xintercept=15, linetype=2) +
  ggtitle('Distribuição em função da Educação') +
  geom_point(aes(x=9, y=100), color='skyblue') +
  geom_point(aes(x=9, y=100), color='black', size=5, shape=1, stroke=1) +
  geom_point(aes(x=15, y=100), color='skyblue') +
  geom_point(aes(x=15, y=100), color='black', size=5, shape=1, stroke=1)

grid.arrange(hist, scat, layout_matrix=matrix(c(1, 2), nrow=1))
```
Consideremos dois casos cujos escores observados são iguai entre si, com valor igual a 100. Considerando exclusivamente a distribuição marginal, ou seja, sem considerar a informação sobre a educação, o percentil desses dois casos é necessariamente idêntico: estando na média, conforme indicado pela linha tracejada no histograma, seu valor é igual a 50%.

Porém, se consideramos a informação sobre a educação, conforme no gráfico de dispersão com as observações (9, 100) e (15, 100) demarcadas, os percentis podem ser diferentes. No caso com nove anos de educação, seu valor encontra-se acima da média de sua subpopulação, que é igual a 91 pontos, resultando num percentil mais alto: 77,3%. No caso com 15 anos de educação, a situação se inverte: para sua subpopulação, o valor esperado para o QI é de 109 pontos, colocando-o no percentil 22,7%.

::::